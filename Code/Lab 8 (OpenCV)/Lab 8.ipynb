{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4a8563",
   "metadata": {},
   "source": [
    "# **OpenCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819de76",
   "metadata": {},
   "source": [
    "### **Installing OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b27f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\admin\\anaconda3\\envs\\alevel\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\admin\\anaconda3\\envs\\alevel\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "# using pip\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415e5c1",
   "metadata": {},
   "source": [
    "### **Reading and Displaying Images with OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed25c61",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m  \u001b[38;5;66;03m# Import OpenCV library\u001b[39;00m\n\u001b[0;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./df2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Read image in BGR format\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMy Image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Display image in window\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Wait for key press to close\u001b[39;00m\n\u001b[0;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2  # Import OpenCV library\n",
    "\n",
    "img = cv2.imread('./df2.jpg')  # Read image in BGR format\n",
    "\n",
    "cv2.imshow(\"My Image\", img)  # Display image in window\n",
    "\n",
    "cv2.waitKey(0)  # Wait for key press to close\n",
    "\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2, matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Read with OpenCV (BGR)\n",
    "bgr = cv2.imread('cat.jpg')\n",
    "\n",
    "# 2. Convert to RGB for display\n",
    "rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 3. Show with Matplotlib\n",
    "plt.imshow(rgb)\n",
    "plt.title('Cat')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252330db",
   "metadata": {},
   "source": [
    "### **Writing and Saving Images in OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d70d4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1367: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvWaitKey'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./amazon.png\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Read image in BGR format\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)  \u001b[38;5;66;03m# Save image to file as 'output.jpg'\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for key press to close\u001b[39;00m\n\u001b[0;32m      8\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1367: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvWaitKey'\n"
     ]
    }
   ],
   "source": [
    "import cv2  # Import OpenCV library\n",
    "\n",
    "img = cv2.imread('./amazon.png')  # Read image in BGR format\n",
    "\n",
    "cv2.imwrite(\"output.jpg\", img)  # Save image to file as 'output.jpg'\n",
    "\n",
    "cv2.waitKey(0)  # Wait for key press to close\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98002cb",
   "metadata": {},
   "source": [
    "### **Working with Video in OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66163039",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:  \u001b[38;5;66;03m# Break if frame not received (end of video)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLive Video\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Display frame in window\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Exit on 'q' key press\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2  # Import OpenCV library\n",
    "\n",
    "# 1. Open Video Source\n",
    "cap = cv2.VideoCapture(0)  # 0 for webcam, or \"video.mp4\" for file\n",
    "\n",
    "# 2. Read & Display Frames\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read frame (ret=True if successful)\n",
    "    if not ret:  # Break if frame not received (end of video)\n",
    "        break\n",
    "    cv2.imshow(\"Live Video\", frame)  # Display frame in window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Exit on 'q' key press\n",
    "        break\n",
    "\n",
    "# 3. Release Resources\n",
    "cap.release()  # Release video source\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7aa96",
   "metadata": {},
   "source": [
    "### **Draw a Line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8423aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create blank black image\n",
    "img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw blue line (thickness=3)\n",
    "# Syntax: (image, start_point, end_point, color(BGR), thickness)\n",
    "cv2.line(img, (50, 50), (200, 50), (255, 0, 0), 3)\n",
    "\n",
    "cv2.imshow('Line', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147938e",
   "metadata": {},
   "source": [
    "### **Draw a Rectangle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b70ca8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw green rectangle (thickness=2)\n",
    "# Syntax: (image, top-left, bottom-right, color, thickness)\n",
    "cv2.rectangle(img, (60, 60), (200, 150), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('Rectangle', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeea5f5",
   "metadata": {},
   "source": [
    "### **Draw a Circle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dddcbe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw filled red circle (thickness=-1 fills)\n",
    "# Syntax: (image, center, radius, color, thickness)\n",
    "cv2.circle(img, (150, 150), 40, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imshow('Circle', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4401871",
   "metadata": {},
   "source": [
    "### **Put Text on Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0d1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw white text (size=1, thickness=2)\n",
    "# Syntax: (image, text, position, font, scale, color, thickness)\n",
    "cv2.putText(img, \"OpenCV\", (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Text', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34064f8",
   "metadata": {},
   "source": [
    "### **Resizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f87db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('./agi.jpg')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Fixed size resizing\n",
    "resized = cv2.resize(img, (300, 200))  # Width=300, Height=200\n",
    "\n",
    "# Proportional scaling\n",
    "scaled = cv2.resize(img, None, fx=0.5, fy=0.5)  # Half size\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Resized (300x200)', resized)\n",
    "cv2.imshow('Scaled (50%)', scaled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380a4c9",
   "metadata": {},
   "source": [
    "### **Cropping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eac7d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('./agi.jpg')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Crop region (y1:y2, x1:x2)\n",
    "cropped = img[150:200, 100:300]  # From (x100,y50) to (x300,y200)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Cropped', cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save cropped image\n",
    "cv2.imwrite('cropped.jpg', cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5d3d7",
   "metadata": {},
   "source": [
    "### **Rotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf48639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('./agi.jpg')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Get image dimensions\n",
    "(h, w) = img.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "\n",
    "# Create rotation matrix (45 degrees)\n",
    "M = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
    "\n",
    "# Apply rotation\n",
    "rotated = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Rotated 45°', rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Bonus: Rotation with different angles\n",
    "for angle in [30, 60, 90]:\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (w, h))\n",
    "    cv2.imshow(f'Rotated {angle}°', rotated)\n",
    "    cv2.waitKey(1000)  # Show each for 1 second\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e5adb",
   "metadata": {},
   "source": [
    "### **BGR to Grayscale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08cb9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image in BGR format\n",
    "img = cv2.imread('./Anthropic.png')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display both images\n",
    "cv2.imshow('Original (BGR)', img)\n",
    "cv2.imshow('Grayscale', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20dac06",
   "metadata": {},
   "source": [
    "### **BGR to RGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99a0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./Anthropic.png')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Convert BGR to RGB\n",
    "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# OpenCV displays in BGR, so we'll convert back for display\n",
    "display_rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "cv2.imshow('Original (BGR)', img)\n",
    "cv2.imshow('RGB Converted', display_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1285581a",
   "metadata": {},
   "source": [
    "### **BGR to HSV (Hue-Saturation-Value)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea22c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./Anthropic.png')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Convert to HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Split channels for individual display\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('HSV', hsv)\n",
    "cv2.imshow('Hue Channel', h)\n",
    "cv2.imshow('Saturation Channel', s)\n",
    "cv2.imshow('Value Channel', v)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631838c",
   "metadata": {},
   "source": [
    "### **BGR to LAB (CIELAB)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d3919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./Anthropic.png')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Convert to LAB\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split channels\n",
    "l, a, b = cv2.split(lab)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('LAB', lab)\n",
    "cv2.imshow('L* (Lightness)', l)\n",
    "cv2.imshow('a* (Green-Red)', a)\n",
    "cv2.imshow('b* (Blue-Yellow)', b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24de28e",
   "metadata": {},
   "source": [
    "### **Simple Thresholding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image in grayscale\n",
    "gray = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if gray is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Apply Binary Thresholding:\n",
    "# If pixel value is greater than 127, it is set to 255, otherwise set to 0.\n",
    "_, thresh_bin = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Apply Inverse Binary Thresholding:\n",
    "# If pixel value is greater than 127, it is set to 0, otherwise set to 255.\n",
    "_, thresh_inv = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Apply Truncated Thresholding:\n",
    "# If pixel value is greater than 127, it is set to 127, otherwise remains unchanged.\n",
    "_, thresh_trunc = cv2.threshold(gray, 127, 255, cv2.THRESH_TRUNC)\n",
    "\n",
    "# Apply Threshold To Zero:\n",
    "# If pixel value is greater than 127, it remains unchanged, otherwise set to 0.\n",
    "_, thresh_tozero = cv2.threshold(gray, 127, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', gray)\n",
    "cv2.imshow('BINARY', thresh_bin)\n",
    "cv2.imshow('BINARY_INV', thresh_inv)\n",
    "cv2.imshow('TRUNC', thresh_trunc)\n",
    "cv2.imshow('TOZERO', thresh_tozero)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5426af5",
   "metadata": {},
   "source": [
    "### **Adaptive Thresholding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be48163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "gray = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if gray is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Adaptive Mean Thresholding: mean of 11x11 block - 2, binary threshold\n",
    "adaptive_mean = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Adaptive Gaussian Thresholding: weighted mean (Gaussian) of 11x11 block - 2, binary threshold\n",
    "adaptive_gauss = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', gray)\n",
    "cv2.imshow('Adaptive Mean', adaptive_mean)\n",
    "cv2.imshow('Adaptive Gaussian', adaptive_gauss)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd45607",
   "metadata": {},
   "source": [
    "### **Otsu's Binarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c194e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otsu's calculated threshold value: 110.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "gray = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if gray is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Otsu's thresholding: automatically calculates optimal threshold value based on image histogram\n",
    "# The first return value is the calculated threshold (e.g., 91.0), second is the binary image\n",
    "_, otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Again get Otsu's calculated threshold value (e.g., 91.0 for your image)\n",
    "thresh_val, _ = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Use the same threshold value explicitly in normal binary thresholding (for comparison)\n",
    "# If pixel > thresh_val, set to 255; else 0\n",
    "_, simple_thresh = cv2.threshold(gray, thresh_val, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(f\"Otsu's calculated threshold value: {thresh_val}\")\n",
    "cv2.imshow('Original', gray)\n",
    "cv2.imshow(\"Otsu's Threshold\", otsu)\n",
    "cv2.imshow(f\"Simple Threshold at {thresh_val}\", simple_thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f60349",
   "metadata": {},
   "source": [
    "### **Canny Edge Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image in grayscale\n",
    "img = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Basic Canny edge detection (recommended ratio: 1:2 or 1:3)\n",
    "edges = cv2.Canny(img, 100, 200)  # Thresholds: low=100, high=200\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Canny Edges (100-200)', edges)\n",
    "\n",
    "# Interactive threshold adjustment window\n",
    "def update_canny(val):\n",
    "    low_thresh = cv2.getTrackbarPos('Low Threshold', 'Canny Edge Demo')\n",
    "    high_thresh = cv2.getTrackbarPos('High Threshold', 'Canny Edge Demo')\n",
    "    edges = cv2.Canny(img, low_thresh, high_thresh)\n",
    "    cv2.imshow('Canny Edges', edges)\n",
    "\n",
    "# Create demo window with trackbars\n",
    "cv2.namedWindow('Canny Edge Demo')\n",
    "cv2.createTrackbar('Low Threshold', 'Canny Edge Demo', 100, 500, update_canny)\n",
    "cv2.createTrackbar('High Threshold', 'Canny Edge Demo', 200, 500, update_canny)\n",
    "\n",
    "# Initial update\n",
    "update_canny(0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e787ef",
   "metadata": {},
   "source": [
    "### **Sobel Operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05977cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image in grayscale\n",
    "gray = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if gray is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Apply Gaussian blur to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Sobel Edge Detection\n",
    "sobelx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=5)  # Horizontal edges\n",
    "sobely = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=5)  # Vertical edges\n",
    "\n",
    "# Convert to absolute values and scale to 8-bit\n",
    "sobelx_abs = cv2.convertScaleAbs(sobelx)\n",
    "sobely_abs = cv2.convertScaleAbs(sobely)\n",
    "\n",
    "# Combine both directions\n",
    "sobel_combined = cv2.addWeighted(sobelx_abs, 0.5, sobely_abs, 0.5, 0)\n",
    "\n",
    "# For comparison, apply Canny edge detection\n",
    "canny_edges = cv2.Canny(blurred, 100, 200)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', gray)\n",
    "cv2.imshow('Sobel X (Horizontal Edges)', sobelx_abs)\n",
    "cv2.imshow('Sobel Y (Vertical Edges)', sobely_abs)\n",
    "cv2.imshow('Sobel Combined', sobel_combined)\n",
    "cv2.imshow('Canny Edges (Comparison)', canny_edges)\n",
    "\n",
    "# Create interactive window for Sobel kernel size\n",
    "def update_sobel(val):\n",
    "    ksize = 2 * cv2.getTrackbarPos('Kernel Size', 'Sobel Demo') + 1  # Ensure odd number\n",
    "    sobelx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    sobely = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    sobelx_abs = cv2.convertScaleAbs(sobelx)\n",
    "    sobely_abs = cv2.convertScaleAbs(sobely)\n",
    "    combined = cv2.addWeighted(sobelx_abs, 0.5, sobely_abs, 0.5, 0)\n",
    "    cv2.imshow('Sobel Combined', combined)\n",
    "\n",
    "cv2.namedWindow('Sobel Demo')\n",
    "cv2.createTrackbar('Kernel Size', 'Sobel Demo', 2, 5, update_sobel)  # 1,3,5,7,9,11\n",
    "update_sobel(0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c6ffb",
   "metadata": {},
   "source": [
    "### **Laplacian Operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a62f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image in grayscale\n",
    "gray = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if gray is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Apply Gaussian blur to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Laplacian Edge Detection\n",
    "laplacian = cv2.Laplacian(blurred, cv2.CV_64F)\n",
    "laplacian_abs = cv2.convertScaleAbs(laplacian)  # Convert to 8-bit\n",
    "\n",
    "# For comparison, apply Sobel and Canny\n",
    "sobelx = cv2.convertScaleAbs(cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=5))\n",
    "sobely = cv2.convertScaleAbs(cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=5))\n",
    "sobel_combined = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "canny_edges = cv2.Canny(blurred, 100, 200)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', gray)\n",
    "cv2.imshow('Laplacian Edges', laplacian_abs)\n",
    "cv2.imshow('Sobel Combined', sobel_combined)\n",
    "cv2.imshow('Canny Edges', canny_edges)\n",
    "cv2.imwrite('laplacian_edges.jpg', laplacian_abs)  # Save Laplacian edges image\n",
    "cv2.imwrite('sobel_combined.jpg', sobel_combined)  # Save Sobel combined image\n",
    "cv2.imwrite('canny_edges.jpg', canny_edges)  # Save Canny edges image\n",
    "\n",
    "# Create interactive window for Laplacian\n",
    "def update_laplacian(val):\n",
    "    ksize = 2 * cv2.getTrackbarPos('Kernel Size', 'Laplacian Demo') + 1  # Ensure odd\n",
    "    laplacian = cv2.Laplacian(blurred, cv2.CV_64F, ksize=ksize)\n",
    "    laplacian_abs = cv2.convertScaleAbs(laplacian)\n",
    "    cv2.imshow('Laplacian Edges', laplacian_abs)\n",
    "\n",
    "cv2.namedWindow('Laplacian Demo')\n",
    "cv2.createTrackbar('Kernel Size', 'Laplacian Demo', 1, 3, update_laplacian)  # 1,3,5,7\n",
    "update_laplacian(0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c51583",
   "metadata": {},
   "source": [
    "### **Drawing Contours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ae935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 contours\n",
      "Contour 0: Area=49766.00, Perimeter=966.00\n",
      "Contour 1: Area=80.00, Perimeter=46.63\n",
      "Contour 2: Area=184.50, Perimeter=58.73\n",
      "Contour 3: Area=15.00, Perimeter=16.00\n",
      "Contour 4: Area=214.00, Perimeter=72.63\n",
      "Contour 5: Area=11.50, Perimeter=15.41\n",
      "Contour 6: Area=184.00, Perimeter=85.31\n",
      "Contour 7: Area=113.00, Perimeter=62.49\n",
      "Contour 8: Area=203.50, Perimeter=94.87\n",
      "Contour 9: Area=170.50, Perimeter=62.87\n",
      "Contour 10: Area=7.00, Perimeter=12.83\n",
      "Contour 11: Area=167.00, Perimeter=84.43\n",
      "Contour 12: Area=257.00, Perimeter=59.94\n",
      "Contour 13: Area=62.00, Perimeter=29.31\n",
      "Contour 14: Area=1358.50, Perimeter=863.80\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('./Anthropic.png')\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "# Convert to grayscale and apply threshold\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(\n",
    "    thresh, \n",
    "    cv2.RETR_TREE,           # Retrieval mode\n",
    "    cv2.CHAIN_APPROX_SIMPLE  # Contour approximation method\n",
    ")\n",
    "\n",
    "# Create a copy to draw on\n",
    "contour_img = img.copy()\n",
    "\n",
    "# Draw all contours (green, thickness=2)\n",
    "cv2.drawContours(\n",
    "    contour_img, \n",
    "    contours, \n",
    "    -1,              # Draw all contours\n",
    "    (0, 255, 0),     # Green color (BGR)\n",
    "    2                # Thickness\n",
    ")\n",
    "\n",
    "# Draw specific contour (red, filled)\n",
    "if len(contours) > 0:\n",
    "    cv2.drawContours(\n",
    "        contour_img, \n",
    "        contours, \n",
    "        0,              # First contour\n",
    "        (0, 0, 255),    # Red color\n",
    "        -1              # Filled contour\n",
    "    )\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Threshold', thresh)\n",
    "cv2.imshow('Contours', contour_img)\n",
    "cv2.imwrite('contours.jpg', contour_img)  # Save contour image\n",
    "cv2.imwrite('Original.jpg', img)  # Save original image\n",
    "\n",
    "# Print contour information\n",
    "print(f\"Found {len(contours)} contours\")\n",
    "for i, cnt in enumerate(contours):\n",
    "    area = cv2.contourArea(cnt)\n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    print(f\"Contour {i}: Area={area:.2f}, Perimeter={perimeter:.2f}\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e1a2b",
   "metadata": {},
   "source": [
    "### **Erosion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a59aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "_, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((5,5), np.uint8)  # 5x5 square kernel\n",
    "eroded = cv2.erode(binary, kernel, iterations=1)\n",
    "\n",
    "cv2.imwrite('eroded_image.jpg', eroded)  # Save the eroded image\n",
    "cv2.imwrite('Original.jpg', binary)  # Save the original binary image\n",
    "cv2.imshow('Original', binary)\n",
    "cv2.imshow('Erosion', eroded)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10122eec",
   "metadata": {},
   "source": [
    "### **Dilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3fa3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "_, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "dilated = cv2.dilate(binary, kernel, iterations=1)\n",
    "\n",
    "cv2.imwrite('dilated_image.jpg', dilated)  # Save the dilated image\n",
    "cv2.imwrite('Original.jpg', binary)  # Save the original binary image\n",
    "cv2.imshow('Original', binary)\n",
    "cv2.imshow('Dilation', dilated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33305fb",
   "metadata": {},
   "source": [
    "### **Opening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf83708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "_, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imwrite('Original.jpg', binary)  # Save the original binary image\n",
    "cv2.imwrite('opened_image.jpg', opened)  # Save the opened image\n",
    "cv2.imshow('Original', binary)\n",
    "cv2.imshow('Opening', opened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab13a09",
   "metadata": {},
   "source": [
    "### **Closing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bfc9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./Anthropic.png', cv2.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    print(\"Error: Image not found\")\n",
    "    exit()\n",
    "\n",
    "_, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imwrite('Original.jpg', binary)  # Save the original binary image\n",
    "cv2.imwrite('closed_image.jpg', closed)  # Save the closed image\n",
    "cv2.imshow('Original', binary)\n",
    "cv2.imshow('Closing', closed)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f7cd8",
   "metadata": {},
   "source": [
    "### **Face Detection with Haar Cascades**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a0733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize webcam (or load image/video)\n",
    "cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale (face detection works on grayscale)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,  # How much the image size is reduced at each scale\n",
    "        minNeighbors=5,   # How many neighbors each candidate rectangle should have\n",
    "        minSize=(30, 30)  # Minimum object size\n",
    "    )\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Blue rectangle\n",
    "        cv2.putText(img, 'Face', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 2)\n",
    "\n",
    "    # Display output\n",
    "    cv2.imshow('Face Detection', img)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2927b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('./face.jpg')\n",
    "\n",
    "# Load classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# Draw rectangles\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "\n",
    "# Save and display\n",
    "cv2.imwrite('detected_faces.jpg', img)\n",
    "cv2.imshow('Faces Found', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6879be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file 'C:\\Users\\Admin\\.u2net\\u2net.onnx'.\n",
      "100%|#######################################| 176M/176M [00:00<00:00, 68.5GB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background removed and saved to output_image.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from rembg import remove  # <-- Add this import\n",
    "\n",
    "input_path = 'Automation.jpg'  # Replace with your input image path\n",
    "output_path = 'output_image.png'  # Replace with your desired output image path\n",
    "\n",
    "input_image = Image.open(input_path)\n",
    "output_image = remove(input_image)  # Remove the background\n",
    "output_image.save(output_path)  # Save the output image\n",
    "print(f\"Background removed and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1207902d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
